{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEpQq7W3bPUH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTn2Aw6IRxLt"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJtj71VKbZbo"
      },
      "outputs": [],
      "source": [
        "#OP Model with L1 norm\n",
        "from tensorflow.python.ops.linalg_ops import norm_v2\n",
        "class OP_main():\n",
        "    \n",
        "    def __init__(self,Data, lam=1/np.sqrt(n1),th=0.000000000000001, rho=1.5, mup=1.25):\n",
        "        \n",
        "        #(Data, lam,th, rho, mup)=value_sets\n",
        "\n",
        "\n",
        "        n1,n2=np.shape(Data)\n",
        "        self.lam=lam #1/np.sqrt(n1)\n",
        "        self.eps=0.000000000000001\n",
        "        self.d_nrom=norm_v2(Data)\n",
        "        norm_two=np.linalg.svd(Data,compute_uv=False)[0]#norm_v2(Data,2)\n",
        "        #print(norm_two)\n",
        "        norm_inf=norm_v2(Data,np.inf)/self.lam\n",
        "        #print(norm_inf)\n",
        "        dual_norm=np.max([norm_two, norm_inf])\n",
        "        Lambda_int=Data/dual_norm\n",
        "        #print(Lambda_int[0,0]) \n",
        "        self.mu=mup/norm_two #1.25\n",
        "        self.maxmu=self.mu*10**(7)\n",
        "        self.rho=rho #1.5\n",
        "        self.stages=200 \n",
        "        self.tol=10**(-7) \n",
        "        \n",
        "        \n",
        "        X_int, E_int= tf.zeros([n1,n2], tf.float64), tf.zeros([n1,n2], tf.float64)\n",
        "        value_sets=(Data, X_int, E_int, Lambda_int)\n",
        "        self.FX, self.FE = self.OP_ADMM_main(value_sets) \n",
        "        self.Elabel=self.getLable(self.FE,th)\n",
        " \n",
        "    def OP_ADMM_main(self, inputs):\n",
        "        (Data, X_int, E_int, Lambda_int) = inputs  \n",
        "        self.X,self.E,self.Lambda  = [],[],[]  \n",
        "        self.E.append(self.Updata_E(Data, X_int, Lambda_int))  \n",
        "        self.X.append(self.Updata_X(Data, self.E[-1], Lambda_int))      \n",
        "        self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], Lambda_int))  \n",
        "        self.mu=np.min([self.mu*self.rho, self.maxmu]) \n",
        "        for stage in range(1,self.stages): \n",
        "            self.E.append(self.Updata_E(Data, self.X[-1], self.Lambda[-1]))  \n",
        "            self.X.append(self.Updata_X(Data, self.E[-1], self.Lambda[-1]))      \n",
        "            self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], self.Lambda[-1]))   \n",
        "            self.mu=np.min([self.mu*self.rho, self.maxmu]) \n",
        "            stopCriterion= norm_v2(Data-self.X[-1]-self.E[-1])/self.d_nrom \n",
        "            print(\"Stop Criterion: {}\".format(stopCriterion)) \n",
        "            if stopCriterion < self.tol:\n",
        "                break \n",
        "        return self.X[-1], self.E[-1]   \n",
        "     \n",
        "\n",
        "     \n",
        "\n",
        "    def Updata_X(self,Data, E, Lambda):\n",
        "        \n",
        "        temp=-E+Data+Lambda/self.mu  \n",
        "        return self.SVT(temp,1/self.mu)\n",
        "\n",
        " \n",
        "   \n",
        "    def SVT(self,X,th):\n",
        "        n1, n2= np.shape(X)\n",
        "        rank=np.min([n1,n2])  \n",
        "        U_int, S_int, VT_int=np.linalg.svd(X, full_matrices=True, compute_uv=True, hermitian=False)\n",
        "        S_int=tf.nn.relu(S_int-tf.multiply(th,tf.ones(np.shape(S_int), tf.float64)))\n",
        "        rank=len(np.where(S_int > self.eps)[0])\n",
        "        if rank==0:\n",
        "            rank=1  \n",
        "        S_int=tf.compat.v1.matrix_diag(S_int) \n",
        "        Ak_int=tf.matmul(tf.matmul(U_int[:,0:rank],S_int[0:rank,0:rank]),VT_int[0:rank,:]) \n",
        "          \n",
        "        return Ak_int    \n",
        " \n",
        "    def Updata_E(self, Data, X, Lambda):\n",
        "      \n",
        "        Temp= Data-X+Lambda/self.mu\n",
        "        return self.sparse_col(  Temp, self.lam/self.mu)\n",
        " \n",
        "\n",
        "   \n",
        "\n",
        "    def sparse_col(self, E, tau): \n",
        "        result=[]\n",
        "        n1,n2=np.shape(E)\n",
        "        for i in range(n2):\n",
        "            result.append(tf.nn.relu(tf.norm(E[:,i])-tau)*E[:,i]/(tf.norm(E[:,i])+self.eps)) \n",
        "        return tf.transpose(result,[1,0])\n",
        "\n",
        "  \n",
        "     \n",
        "\n",
        "    def Updata_Lambda(self, Data, X, E, Lambda):\n",
        "        Lambda= Lambda+tf.multiply(self.mu, Data-X-E)\n",
        "        return Lambda\n",
        " \n",
        "\n",
        "    def getLable(self, E,th): \n",
        "        Elabel=[]\n",
        "        n1,n2=np.shape(E)\n",
        "        for i in range(n2):\n",
        "            if tf.norm(E[:,i])>th:\n",
        "                Elabel.append(1)\n",
        "            else:\n",
        "                Elabel.append(0)\n",
        "        return Elabel\n",
        "         \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo7PFl5r_0-d",
        "outputId": "2e8f3425-cc80-4dde-e19a-ace4d40154c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop Criterion: 0.02771651236316883\n",
            "Stop Criterion: 0.017384501214288788\n",
            "Stop Criterion: 0.004953136813105215\n",
            "Stop Criterion: 0.0012521199148616802\n",
            "Stop Criterion: 0.0002414259085647203\n",
            "Stop Criterion: 3.704678373148938e-05\n",
            "Stop Criterion: 7.225579794613062e-06\n",
            "Stop Criterion: 2.2373322264342416e-06\n",
            "Stop Criterion: 8.001266062565949e-07\n",
            "Stop Criterion: 3.0496679119347266e-07\n",
            "Stop Criterion: 1.2169189011155522e-07\n",
            "Stop Criterion: 5.02008332645738e-08\n",
            "[1, 0, 0]\n",
            "tf.Tensor(\n",
            "[[ 0.79596435  0.          0.        ]\n",
            " [ 0.4636718   0.          0.        ]\n",
            " [-0.24470637  0.          0.        ]], shape=(3, 3), dtype=float64)\n"
          ]
        }
      ],
      "source": [
        "# test sample\n",
        "Data=np.array([[7,1,2],[5,2,4],[0,3,6]], np.float64)\n",
        "n1,n2=np.shape(Data)\n",
        "lam=1.3 #1/np.sqrt(n1)\n",
        "th=0.0000001\n",
        "rho=1.5\n",
        "mup=1.25\n",
        "H=OP_main(Data,lam,th,rho,mup)\n",
        "print(H.Elabel)\n",
        "print(H.FE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWB5DJv9RxLw"
      },
      "outputs": [],
      "source": [
        "#OP model with GST\n",
        "from tensorflow.python.ops.linalg_ops import norm_v2\n",
        "class OPGST_main():\n",
        "    \n",
        "    def __init__(self, Data, lam=1/np.sqrt(n1),th=0.000000000000001, rho=1.5, mup=1.25,p=1):\n",
        "        \n",
        "         \n",
        "\n",
        "        self.p=p\n",
        "        n1,n2=np.shape(Data)\n",
        "        self.lam=lam  \n",
        "        self.eps=0.000000000000001\n",
        "        self.d_nrom=norm_v2(Data)\n",
        "        norm_two=np.linalg.svd(Data,compute_uv=False)[0] \n",
        "        norm_inf=norm_v2(Data,np.inf)/self.lam \n",
        "        dual_norm=np.max([norm_two, norm_inf])\n",
        "        Lambda_int=Data/dual_norm \n",
        "        self.mu=mup/norm_two #1.25\n",
        "        self.maxmu=self.mu*10**(7)\n",
        "        self.rho=rho  \n",
        "        self.stages=200 \n",
        "        self.tol=10**(-7) \n",
        "        \n",
        "        X_int, E_int= tf.zeros([n1,n2], tf.float64), tf.zeros([n1,n2], tf.float64)\n",
        "        value_sets=(Data, X_int, E_int, Lambda_int)\n",
        "        self.FX, self.FE = self.OP_ADMM_main(value_sets) \n",
        "        self.Elabel=self.getLable(self.FE,th)\n",
        " \n",
        "    def OP_ADMM_main(self, inputs):\n",
        "        (Data, X_int, E_int, Lambda_int) = inputs  \n",
        "        self.X,self.E,self.Lambda  = [],[],[]  \n",
        "        self.E.append(self.Updata_E(Data, X_int, Lambda_int))  \n",
        "        self.X.append(self.Updata_X(Data, self.E[-1], Lambda_int))      \n",
        "        self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], Lambda_int))  \n",
        "        self.mu=np.min([self.mu*self.rho, self.maxmu])   \n",
        "        for stage in range(1,self.stages): \n",
        "            self.E.append(self.Updata_E(Data, self.X[-1], self.Lambda[-1]))  \n",
        "            self.X.append(self.Updata_X(Data, self.E[-1], self.Lambda[-1]))      \n",
        "            self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], self.Lambda[-1]))   \n",
        "            self.mu=np.min([self.mu*self.rho, self.maxmu]) \n",
        "            stopCriterion= norm_v2(Data-self.X[-1]-self.E[-1])/self.d_nrom \n",
        "            print(\"Stop Criterion: {}\".format(stopCriterion)) \n",
        "            if stopCriterion < self.tol:\n",
        "                break \n",
        "        return self.X[-1], self.E[-1]   \n",
        "     \n",
        "\n",
        "     \n",
        "\n",
        "    def Updata_X(self,Data, E, Lambda): \n",
        "      \n",
        "        temp=-E+Data+Lambda/self.mu  \n",
        "        return self.SVT(temp,1/self.mu)\n",
        "\n",
        " \n",
        "   \n",
        "    def SVT(self,X,th):\n",
        "        n1, n2= np.shape(X)\n",
        "        rank=np.min([n1,n2])  \n",
        "        U_int, S_int, VT_int=np.linalg.svd(X, full_matrices=True, compute_uv=True, hermitian=False)\n",
        "        S_int=self.Generalized_Soft_Thresholding(S_int,th,self.p)\n",
        "        rank=len(np.where(S_int > self.eps)[0])\n",
        "        if rank==0:\n",
        "            rank=1  \n",
        "        S_int=tf.compat.v1.matrix_diag(S_int) \n",
        "        Ak_int=tf.matmul(tf.matmul(U_int[:,0:rank],S_int[0:rank,0:rank]),VT_int[0:rank,:]) \n",
        "          \n",
        "        return Ak_int    \n",
        " \n",
        "    def Updata_E(self, Data, X, Lambda):\n",
        "        \n",
        "        Temp= Data-X+Lambda/self.mu\n",
        "        return self.sparse_col(  Temp, self.lam/self.mu)\n",
        " \n",
        "\n",
        "   \n",
        "\n",
        "    def sparse_col(self, E, tau): \n",
        "        result=[]\n",
        "        n1,n2=np.shape(E)\n",
        "        for i in range(n2):\n",
        "            result.append(self.Generalized_Soft_Thresholding(tf.norm(E[:,i]),tau,self.p)*E[:,i]/(tf.norm(E[:,i])+self.eps)) \n",
        "        return tf.transpose(result,[1,0])\n",
        "\n",
        "  \n",
        "     \n",
        "\n",
        "    def Updata_Lambda(self, Data, X, E, Lambda):\n",
        "        Lambda= Lambda+tf.multiply(self.mu, Data-X-E)\n",
        "        return Lambda\n",
        " \n",
        "\n",
        "    def getLable(self, E,th): \n",
        "        Elabel=[]\n",
        "        n1,n2=np.shape(E)\n",
        "        for i in range(n2):\n",
        "            if tf.norm(E[:,i])>th:\n",
        "                Elabel.append(1)\n",
        "            else:\n",
        "                Elabel.append(0)\n",
        "        return Elabel\n",
        "         \n",
        "        \n",
        "    def Generalized_Soft_Thresholding(self,S,weight,p):\n",
        "        #diagS: a vector\n",
        "        #weight: a value\n",
        "        if np.shape(S) == ():\n",
        "            diagS=[S]\n",
        "        else:\n",
        "            diagS=S \n",
        "        J=5 \n",
        "        sigma0   =    np.abs(diagS)\n",
        "        tau_GST  =   (2*weight*(1-p))**(1/(2-p))   +   p*weight*(2*(1-p)*weight)**((p-1)/(2-p)) \n",
        "        Delta=[];\n",
        "        for i in range(len(diagS)):\n",
        "                if sigma0[i]>tau_GST: \n",
        "                    delta=sigma0[i]  \n",
        "                    for k in range(J): \n",
        "                            delta=sigma0[i]-weight*p*delta**(p-1)           \n",
        "                            k=k+1  \n",
        "                    Delta.append(np.sign(diagS[i])*delta)  \n",
        "                else:\n",
        "                    Delta.append(0) \n",
        "        if np.shape(S) == ():\n",
        "            return np.array(Delta[0],np.float64) \n",
        "        else:\n",
        "            return np.array(Delta,np.float64) \n",
        "\n",
        "\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U13IgAInRxLx",
        "outputId": "84cf7056-43cf-4e06-a05b-b9ed697b435d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop Criterion: 0.06968655348307115\n",
            "Stop Criterion: 0.033549524337254284\n",
            "Stop Criterion: 0.014605080229469644\n",
            "Stop Criterion: 0.0064766240023816065\n",
            "Stop Criterion: 0.003569636981640282\n",
            "Stop Criterion: 0.0013102399929058853\n",
            "Stop Criterion: 0.00015949477959337335\n",
            "Stop Criterion: 4.1360014467796234e-05\n",
            "Stop Criterion: 1.8868610062230848e-05\n",
            "Stop Criterion: 5.632345409268264e-06\n",
            "Stop Criterion: 2.2922222900111563e-06\n",
            "Stop Criterion: 1.0333381822169081e-06\n",
            "Stop Criterion: 4.706433338958856e-07\n",
            "Stop Criterion: 2.0817622293720724e-07\n",
            "Stop Criterion: 9.149778874305399e-08\n",
            "[1, 0, 0]\n",
            "tf.Tensor(\n",
            "[[ 6.38093858 -0.          0.        ]\n",
            " [ 3.76187763  0.          0.        ]\n",
            " [-1.85718315  0.          0.        ]], shape=(3, 3), dtype=float64)\n"
          ]
        }
      ],
      "source": [
        "# test sample\n",
        "Data=np.array([[7,1,2],[5,2,4],[0,3,6]], np.float64)\n",
        "n1,n2=np.shape(Data)\n",
        "lam=1.1 #1/np.sqrt(n1)\n",
        "th=0.0000001\n",
        "rho=1.5\n",
        "mup=1.25\n",
        "p=0.8\n",
        "#value_sets=(Data,lam,th,rho,mup,p)\n",
        "HGST=OPGST_main(Data,lam,th,rho,mup,p)\n",
        "print(HGST.Elabel)\n",
        "print(HGST.FE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJMjsUOzRxLx"
      },
      "outputs": [],
      "source": [
        "#OP model with ETP\n",
        "from tensorflow.python.ops.linalg_ops import norm_v2\n",
        "class OPETP_main():\n",
        "    \n",
        "    def __init__(self, Data, lam=1/np.sqrt(n1),th=0.000000000000001, rho=1.5, mup=1.25,p=1,Maxiter=1000,tol=10**(-7)):\n",
        "        \n",
        "       \n",
        "\n",
        "        self.p=p\n",
        "        n1,n2=np.shape(Data)\n",
        "        self.lam=lam  \n",
        "        self.eps=0.000000000000001\n",
        "        self.d_nrom=norm_v2(Data)\n",
        "        norm_two=np.linalg.svd(Data,compute_uv=False)[0] \n",
        "        norm_inf=norm_v2(Data,np.inf)/self.lam \n",
        "        dual_norm=np.max([norm_two, norm_inf])\n",
        "        Lambda_int=Data/dual_norm \n",
        "        self.mu=mup/norm_two  \n",
        "        self.maxmu=self.mu*10**(7)\n",
        "        self.rho=rho #1.5\n",
        "        self.stages=200\n",
        "        self.tol=10**(-7) \n",
        "        \n",
        "        X_int, E_int= tf.zeros([n1,n2], tf.float64), tf.zeros([n1,n2], tf.float64)\n",
        "        value_sets=(Data, X_int, E_int, Lambda_int)\n",
        "        self.FX, self.FE = self.OP_ADMM_main(value_sets) \n",
        "        self.Elabel=self.getLable(self.FE,th)\n",
        " \n",
        "    def OP_ADMM_main(self, inputs):\n",
        "        (Data, X_int, E_int, Lambda_int) = inputs  \n",
        "        self.X,self.E,self.Lambda  = [],[],[]  \n",
        "        self.E.append(self.Updata_E(Data, X_int, Lambda_int))  \n",
        "        self.X.append(self.Updata_X(Data, self.E[-1], Lambda_int))      \n",
        "        self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], Lambda_int))  \n",
        "        self.mu=np.min([self.mu*self.rho, self.maxmu])   \n",
        "        for stage in range(1,self.stages): \n",
        "            self.E.append(self.Updata_E(Data, self.X[-1], self.Lambda[-1]))  \n",
        "            self.X.append(self.Updata_X(Data, self.E[-1], self.Lambda[-1]))      \n",
        "            self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], self.Lambda[-1]))   \n",
        "            self.mu=np.min([self.mu*self.rho, self.maxmu]) \n",
        "            stopCriterion= norm_v2(Data-self.X[-1]-self.E[-1])/self.d_nrom \n",
        "            print(\"Stop Criterion: {}\".format(stopCriterion)) \n",
        "            if stopCriterion < self.tol:\n",
        "                break \n",
        "        return self.X[-1], self.E[-1]   \n",
        "     \n",
        "\n",
        "     \n",
        "\n",
        "    def Updata_X(self,Data, E, Lambda): \n",
        "      \n",
        "        temp=-E+Data+Lambda/self.mu  \n",
        "        return self.SVT(temp,1/self.mu)\n",
        "\n",
        " \n",
        "   \n",
        "    def SVT(self,X,th):\n",
        "        n1, n2= np.shape(X)\n",
        "        rank=np.min([n1,n2])  \n",
        "        U_int, S_int, VT_int=np.linalg.svd(X, full_matrices=True, compute_uv=True, hermitian=False)\n",
        "        S_int=self.GAI_ETP(S_int,th,self.p)\n",
        "        rank=len(np.where(S_int > self.eps)[0])\n",
        "        if rank==0:\n",
        "            rank=1  \n",
        "        S_int=tf.compat.v1.matrix_diag(S_int) \n",
        "        Ak_int=tf.matmul(tf.matmul(U_int[:,0:rank],S_int[0:rank,0:rank]),VT_int[0:rank,:]) \n",
        "          \n",
        "        return Ak_int    \n",
        " \n",
        "    def Updata_E(self, Data, X, Lambda): \n",
        "        Temp= Data-X+Lambda/self.mu \n",
        "        return self.sparse_col(  Temp, self.lam/self.mu)\n",
        " \n",
        "\n",
        "   \n",
        "\n",
        "    def sparse_col(self, E, tau): \n",
        "        result=[]\n",
        "        n1,n2=np.shape(E)\n",
        "        for i in range(n2):\n",
        "            result.append(self.GAI_ETP(tf.norm(E[:,i]),tau,self.p)*E[:,i]/(tf.norm(E[:,i])+self.eps)) \n",
        "        return tf.transpose(result,[1,0])\n",
        "\n",
        "  \n",
        "     \n",
        "\n",
        "    def Updata_Lambda(self, Data, X, E, Lambda):\n",
        "        Lambda= Lambda+tf.multiply(self.mu, Data-X-E)\n",
        "        return Lambda\n",
        " \n",
        "\n",
        "    def getLable(self, E,th): \n",
        "        Elabel=[]\n",
        "        n1,n2=np.shape(E)\n",
        "        for i in range(n2):\n",
        "            if tf.norm(E[:,i])>th:\n",
        "                Elabel.append(1)\n",
        "            else:\n",
        "                Elabel.append(0)\n",
        "        return Elabel\n",
        "         \n",
        "        \n",
        "   \n",
        "\n",
        "    def GAI_ETP(self,xi,lambd,gamma,Iter=10,tol=10**(-6)): \n",
        "        a0=np.max([np.log((1-np.exp(-gamma))/(lambd*gamma**2))/(-gamma),0]) \n",
        "        delta=a0+self.ETP_gradient(a0,gamma,lambd) \n",
        "        if np.shape(xi) == ():\n",
        "            x=[xi]\n",
        "        else:\n",
        "            x=xi\n",
        "        n=len(x)\n",
        "        y=[]\n",
        " \n",
        "\n",
        "     \n",
        "        for j in range(n):\n",
        "            gradient_g= self.ETP_gradient(x[j],gamma,lambd)\n",
        "            if gradient_g==0:\n",
        "                BARx_b=x[j] \n",
        "            else:\n",
        "                if delta<x[j]:\n",
        "                    a=x[j]\n",
        "                    sto=0\n",
        "                    kkk=0\n",
        "                    while sto==0:\n",
        "                        kkk=kkk+1\n",
        "                        a1=x[j]-self.ETP_gradient(a,gamma,lambd)\n",
        "                        a2=x[j]-self.ETP_gradient(a1,gamma,lambd) \n",
        "                        if np.abs(a2-2*a1+a)<tol or kkk>=Iter:\n",
        "                            if np.abs(a2-2*a1+a)<self.eps:\n",
        "                                BARx_b=a2\n",
        "                            else:\n",
        "                                BARx_b=a1-(a2-a1)*(a1-a)/(a2-2*a1+a)\n",
        "                            break\n",
        "                        a=a1-(a2-a1)*(a1-a)/(a2-2*a1+a)  \n",
        "                else:\n",
        "                    BARx_b=a0\n",
        "            if self.ETP_fun(BARx_b,x[j],gamma,lambd)<=self.ETP_fun(0,x[j],gamma,lambd):\n",
        "                y.append(BARx_b)   \n",
        "            else:\n",
        "                y.append(0)\n",
        "                    \n",
        "        if np.shape(xi) == ():\n",
        "            return np.array(y[0],np.float64) \n",
        "        else:\n",
        "            return np.array(y,np.float64)\n",
        "      \n",
        "           \n",
        "    #ETP's gradient \n",
        "    def ETP_gradient(self,x,gamma,lambd):\n",
        "        gradient_g=gamma*lambd*np.exp(-gamma*x)/(1-np.exp(-gamma)) \n",
        "        return gradient_g\n",
        " \n",
        "    def ETP_fun(self,x,y,gamma,lambd):\n",
        "        g=1/2*(y-x)**2+lambd*(1-np.exp(-gamma*x))/(1-np.exp(-gamma))\n",
        "        return g   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rT6ud3tRxLz",
        "outputId": "1988c5db-05ad-40a0-c29a-aef1196841ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop Criterion: 2.4261219471294536e-16\n",
            "[1, 0, 0]\n",
            "tf.Tensor(\n",
            "[[ 7.00000000e+00 -0.00000000e+00  0.00000000e+00]\n",
            " [ 5.00000000e+00 -0.00000000e+00  0.00000000e+00]\n",
            " [-5.92118946e-15 -0.00000000e+00  0.00000000e+00]], shape=(3, 3), dtype=float64)\n"
          ]
        }
      ],
      "source": [
        "# test sample\n",
        "Data=np.array([[7,1,2],[5,2,4],[0,3,6]], np.float64)\n",
        "n1,n2=np.shape(Data)\n",
        "lam=6#1/np.sqrt(n1)\n",
        "th=0.0000001\n",
        "rho=1.5\n",
        "mup=1.25\n",
        "p=10 \n",
        "HETP=OPETP_main(Data,lam,th,rho,mup,p)\n",
        "print(HETP.Elabel)\n",
        "print(HETP.FE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYuaKvWoRxL1"
      },
      "outputs": [],
      "source": [
        "# OP Model with LOG\n",
        "from tensorflow.python.ops.linalg_ops import norm_v2\n",
        "class OPLOG_main():\n",
        "    \n",
        "    def __init__(self, Data, lam=1/np.sqrt(n1),th=0.000000000000001, rho=1.5, mup=1.25,p=1,Maxiter=1000,tol=10**(-7) ):\n",
        "        \n",
        "         \n",
        "\n",
        "        self.p=p\n",
        "        n1,n2=np.shape(Data)\n",
        "        self.lam=lam  \n",
        "        self.eps=0.000000000000001\n",
        "        self.d_nrom=norm_v2(Data)\n",
        "        norm_two=np.linalg.svd(Data,compute_uv=False)[0] \n",
        "        norm_inf=norm_v2(Data,np.inf)/self.lam \n",
        "        dual_norm=np.max([norm_two, norm_inf])\n",
        "        Lambda_int=Data/dual_norm \n",
        "        self.mu=mup/norm_two #1.25\n",
        "        self.maxmu=self.mu*10**(7)\n",
        "        self.rho=rho #1.5\n",
        "        self.stages=Maxiter\n",
        "        self.tol=tol\n",
        "        \n",
        "        X_int, E_int= tf.zeros([n1,n2], tf.float64), tf.zeros([n1,n2], tf.float64)\n",
        "        value_sets=(Data, X_int, E_int, Lambda_int)\n",
        "        self.FX, self.FE = self.OP_ADMM_main(value_sets) \n",
        "        self.Elabel=self.getLable(self.FE,th)\n",
        " \n",
        "    def OP_ADMM_main(self, inputs):\n",
        "        (Data, X_int, E_int, Lambda_int) = inputs  \n",
        "        self.X,self.E,self.Lambda  = [],[],[]  \n",
        "        self.E.append(self.Updata_E(Data, X_int, Lambda_int))  \n",
        "        self.X.append(self.Updata_X(Data, self.E[-1], Lambda_int))      \n",
        "        self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], Lambda_int))  \n",
        "        self.mu=np.min([self.mu*self.rho, self.maxmu])  \n",
        "        for stage in range(1,self.stages): \n",
        "            self.E.append(self.Updata_E(Data, self.X[-1], self.Lambda[-1]))  \n",
        "            self.X.append(self.Updata_X(Data, self.E[-1], self.Lambda[-1]))      \n",
        "            self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], self.Lambda[-1]))   \n",
        "            self.mu=np.min([self.mu*self.rho, self.maxmu]) \n",
        "            stopCriterion= norm_v2(Data-self.X[-1]-self.E[-1])/self.d_nrom \n",
        "            print(\"Stop Criterion: {}\".format(stopCriterion)) \n",
        "            if stopCriterion < self.tol:\n",
        "                break \n",
        "        return self.X[-1], self.E[-1]   \n",
        "     \n",
        "\n",
        "     \n",
        "\n",
        "    def Updata_X(self,Data, E, Lambda): \n",
        "        temp=-E+Data+Lambda/self.mu  \n",
        "        return self.SVT(temp,1/self.mu)\n",
        "\n",
        " \n",
        "   \n",
        "    def SVT(self,X,th):\n",
        "        n1, n2= np.shape(X)\n",
        "        rank=np.min([n1,n2])  \n",
        "        U_int, S_int, VT_int=np.linalg.svd(X, full_matrices=True, compute_uv=True, hermitian=False)\n",
        "        S_int=self.GAI_LOG(S_int,th,self.p)\n",
        "        rank=len(np.where(S_int > self.eps)[0])\n",
        "        if rank==0:\n",
        "            rank=1  \n",
        "        S_int=tf.compat.v1.matrix_diag(S_int) \n",
        "        Ak_int=tf.matmul(tf.matmul(U_int[:,0:rank],S_int[0:rank,0:rank]),VT_int[0:rank,:]) \n",
        "          \n",
        "        return Ak_int    \n",
        " \n",
        "    def Updata_E(self, Data, X, Lambda):\n",
        "        \n",
        "        Temp= Data-X+Lambda/self.mu\n",
        "        return self.sparse_col(  Temp, self.lam/self.mu)\n",
        " \n",
        "\n",
        "   \n",
        "\n",
        "    def sparse_col(self, E, tau): \n",
        "        result=[]\n",
        "        n1,n2=np.shape(E)\n",
        "        for i in range(n2):\n",
        "            result.append(self.GAI_LOG(tf.norm(E[:,i]),tau,self.p)*E[:,i]/(tf.norm(E[:,i])+self.eps)) \n",
        "        return tf.transpose(result,[1,0])\n",
        "\n",
        "  \n",
        "     \n",
        "\n",
        "    def Updata_Lambda(self, Data, X, E, Lambda):\n",
        "        Lambda= Lambda+tf.multiply(self.mu, Data-X-E)\n",
        "        return Lambda\n",
        " \n",
        "\n",
        "    def getLable(self, E,th): \n",
        "        Elabel=[]\n",
        "        n1,n2=np.shape(E)\n",
        "        for i in range(n2):\n",
        "            if tf.norm(E[:,i])>th:\n",
        "                Elabel.append(1)\n",
        "            else:\n",
        "                Elabel.append(0)\n",
        "        return Elabel\n",
        "         \n",
        "\n",
        "    def LOG_th(self,x,tau,lambd):\n",
        "        x0=np.sqrt(2*lambd)-tau\n",
        "        y=np.sign(np.max([x-x0,0]))*(1/2)*((x-tau)+np.sqrt((x+tau)**2-2*lambd))+np.sign(np.max([-x0-x,0]))*(1/2)*((x+tau)+np.sqrt((x-tau)**2-2*lambd))\n",
        "        return y\n",
        "    \n",
        "    \n",
        "    \n",
        "    def GAI_LOG(self,xi,lambd,gamma,Iter=10,tol=10**(-4)):\n",
        "        #Iter=10; \n",
        "    \n",
        "        a0=np.max([np.sqrt(lambd)-gamma,0])\n",
        "        #print(a0)\n",
        "        delta=a0+self.LOG_gradient(a0,gamma,lambd)\n",
        "        #print(delta) \n",
        "        if np.shape(xi) == ():\n",
        "            x=[xi]\n",
        "        else:\n",
        "            x=xi\n",
        "        n=len(x)\n",
        "        y=[] \n",
        "     \n",
        "        for j in range(n):\n",
        "            gradient_g= self.LOG_gradient(x[j],gamma,lambd)\n",
        "            if gradient_g==0:\n",
        "                BARx_b=x[j] \n",
        "            else:\n",
        "                if delta<x[j]:\n",
        "                    a=x[j]\n",
        "                    sto=0\n",
        "                    kkk=0\n",
        "                    while sto==0:\n",
        "                        kkk=kkk+1\n",
        "                        a1=x[j]-self.LOG_gradient(a,gamma,lambd)\n",
        "                        a2=x[j]-self.LOG_gradient(a1,gamma,lambd) \n",
        "                        if np.abs(a2-2*a1+a)<tol or kkk>=Iter:\n",
        "                            if np.abs(a2-2*a1+a)<self.eps:\n",
        "                                BARx_b=a2\n",
        "                            else:\n",
        "                                BARx_b=a1-(a2-a1)*(a1-a)/(a2-2*a1+a)\n",
        "                            break\n",
        "                        a=a1-(a2-a1)*(a1-a)/(a2-2*a1+a) \n",
        "                        #print(a)\n",
        "                else:\n",
        "                    BARx_b=a0\n",
        "                if self.LOG_fun(BARx_b,x[j],gamma,lambd)<=self.LOG_fun(0,x[j],gamma,lambd):\n",
        "                    y.append(BARx_b)   \n",
        "                else:\n",
        "                    y.append(0)\n",
        "        \n",
        "        if np.shape(xi) == ():\n",
        "            return np.array(y[0],np.float64) \n",
        "        else:\n",
        "            return np.array(y,np.float64)\n",
        "      \n",
        "           \n",
        "\n",
        "\n",
        "#LOG's gradient \n",
        "    def LOG_gradient(self,x,gamma,lambd):\n",
        "        gradient_g=lambd/(gamma+x)\n",
        "        return gradient_g\n",
        " \n",
        "    def LOG_fun(self,x,y,gamma,lambd):\n",
        "        g=1/2*(y-x)**2+lambd*(np.log(gamma+x))\n",
        "        return g\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k15P-Xl7RxL2",
        "outputId": "a9b11163-89cb-4054-aa6f-be26ad6f10bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop Criterion: 0.0026366742250366285\n",
            "Stop Criterion: 0.0016644579340530348\n",
            "Stop Criterion: 0.000599125718678935\n",
            "Stop Criterion: 0.0002322995954917029\n",
            "Stop Criterion: 9.510577059916805e-05\n",
            "Stop Criterion: 4.023698178748473e-05\n",
            "Stop Criterion: 1.736866056257894e-05\n",
            "Stop Criterion: 7.594570802103793e-06\n",
            "Stop Criterion: 3.351016147898213e-06\n",
            "Stop Criterion: 1.4909650435274126e-06\n",
            "Stop Criterion: 4.1122749716615434e-07\n",
            "Stop Criterion: 1.6144436485787669e-07\n",
            "Stop Criterion: 7.165158124760496e-08\n",
            "[1, 0, 0]\n",
            "tf.Tensor(\n",
            "[[ 1.51067052 -0.         -0.        ]\n",
            " [ 1.03186057  0.          0.        ]\n",
            " [-0.11010954  0.          0.        ]], shape=(3, 3), dtype=float64)\n"
          ]
        }
      ],
      "source": [
        "# test sample\n",
        "Data=np.array([[7,1,2],[5,2,4],[0,3,6]], np.float64)\n",
        "n1,n2=np.shape(Data)\n",
        "lam=9#1/np.sqrt(n1)\n",
        "th=0.0000001\n",
        "rho=1.5\n",
        "mup=1.25\n",
        "p=23 \n",
        "HLOG=OPLOG_main(Data,lam,th,rho,mup,p)\n",
        "print(HLOG.Elabel)\n",
        "print(HLOG.FE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "OP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
