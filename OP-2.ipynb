{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "SEpQq7W3bPUH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "id": "yJtj71VKbZbo"
   },
   "outputs": [],
   "source": [
    "#OP Model with L1 norm\n",
    "from tensorflow.python.ops.linalg_ops import norm_v2\n",
    "class OP_main():\n",
    "    \n",
    "    def __init__(self,Data, lam=1/np.sqrt(n1),th=0.000000000000001, rho=1.5, mup=1.25):\n",
    "        \n",
    "        #(Data, lam,th, rho, mup)=value_sets\n",
    "\n",
    "\n",
    "        n1,n2=np.shape(Data)\n",
    "        self.lam=lam #1/np.sqrt(n1)\n",
    "        self.eps=0.000000000000001\n",
    "        self.d_nrom=norm_v2(Data)\n",
    "        norm_two=np.linalg.svd(Data,compute_uv=False)[0]#norm_v2(Data,2)\n",
    "        #print(norm_two)\n",
    "        norm_inf=norm_v2(Data,np.inf)/self.lam\n",
    "        #print(norm_inf)\n",
    "        dual_norm=np.max([norm_two, norm_inf])\n",
    "        Lambda_int=Data/dual_norm\n",
    "        #print(Lambda_int[0,0]) \n",
    "        self.mu=mup/norm_two #1.25\n",
    "        self.maxmu=self.mu*10**(7)\n",
    "        self.rho=rho #1.5\n",
    "        self.stages=200 \n",
    "        self.tol=10**(-7) \n",
    "        \n",
    "        \n",
    "        X_int, E_int= tf.zeros([n1,n2], tf.float64), tf.zeros([n1,n2], tf.float64)\n",
    "        value_sets=(Data, X_int, E_int, Lambda_int)\n",
    "        self.FX, self.FE = self.OP_ADMM_main(value_sets) \n",
    "        self.Elabel=self.getLable(self.FE,th)\n",
    " \n",
    "    def OP_ADMM_main(self, inputs):\n",
    "        (Data, X_int, E_int, Lambda_int) = inputs  \n",
    "        self.X,self.E,self.Lambda  = [],[],[]  \n",
    "        self.E.append(self.Updata_E(Data, X_int, Lambda_int))  \n",
    "        self.X.append(self.Updata_X(Data, self.E[-1], Lambda_int))      \n",
    "        self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], Lambda_int))  \n",
    "        self.mu=np.min([self.mu*self.rho, self.maxmu])\n",
    "        #print(self.E[-1][0,0])\n",
    "        #print(self.X[-1][0,0])  \n",
    "        #print(self.Lambda[-1][0,0])  \n",
    "        for stage in range(1,self.stages): \n",
    "            self.E.append(self.Updata_E(Data, self.X[-1], self.Lambda[-1]))  \n",
    "            self.X.append(self.Updata_X(Data, self.E[-1], self.Lambda[-1]))      \n",
    "            self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], self.Lambda[-1]))   \n",
    "            self.mu=np.min([self.mu*self.rho, self.maxmu]) \n",
    "            stopCriterion= norm_v2(Data-self.X[-1]-self.E[-1])/self.d_nrom \n",
    "            print(\"Stop Criterion: {}\".format(stopCriterion))\n",
    "            #print(self.E[-1][0,0])\n",
    "            #print(self.X[-1][0,0]) \n",
    "            #print(self.Lambda[-1][0,0])\n",
    "            if stopCriterion < self.tol:\n",
    "                break \n",
    "        return self.X[-1], self.E[-1]   \n",
    "     \n",
    "\n",
    "     \n",
    "\n",
    "    def Updata_X(self,Data, E, Lambda):\n",
    "        \n",
    "        temp=-E+Data+Lambda/self.mu  \n",
    "        return self.SVT(temp,1/self.mu)\n",
    "\n",
    " \n",
    "   \n",
    "    def SVT(self,X,th):\n",
    "        n1, n2= np.shape(X)\n",
    "        rank=np.min([n1,n2])  \n",
    "        U_int, S_int, VT_int=np.linalg.svd(X, full_matrices=True, compute_uv=True, hermitian=False)\n",
    "        S_int=tf.nn.relu(S_int-tf.multiply(th,tf.ones(np.shape(S_int), tf.float64)))\n",
    "        rank=len(np.where(S_int > self.eps)[0])\n",
    "        if rank==0:\n",
    "            rank=1  \n",
    "        S_int=tf.compat.v1.matrix_diag(S_int) \n",
    "        Ak_int=tf.matmul(tf.matmul(U_int[:,0:rank],S_int[0:rank,0:rank]),VT_int[0:rank,:]) \n",
    "          \n",
    "        return Ak_int    \n",
    " \n",
    "    def Updata_E(self, Data, X, Lambda):\n",
    "      \n",
    "        Temp= Data-X+Lambda/self.mu\n",
    "        return self.sparse_col(  Temp, self.lam/self.mu)\n",
    " \n",
    "\n",
    "   \n",
    "\n",
    "    def sparse_col(self, E, tau): \n",
    "        result=[]\n",
    "        n1,n2=np.shape(E)\n",
    "        for i in range(n2):\n",
    "            result.append(tf.nn.relu(tf.norm(E[:,i])-tau)*E[:,i]/(tf.norm(E[:,i])+self.eps)) \n",
    "        return tf.transpose(result,[1,0])\n",
    "\n",
    "  \n",
    "     \n",
    "\n",
    "    def Updata_Lambda(self, Data, X, E, Lambda):\n",
    "        Lambda= Lambda+tf.multiply(self.mu, Data-X-E)\n",
    "        return Lambda\n",
    " \n",
    "\n",
    "    def getLable(self, E,th): \n",
    "        Elabel=[]\n",
    "        n1,n2=np.shape(E)\n",
    "        for i in range(n2):\n",
    "            if tf.norm(E[:,i])>th:\n",
    "                Elabel.append(1)\n",
    "            else:\n",
    "                Elabel.append(0)\n",
    "        return Elabel\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bo7PFl5r_0-d",
    "outputId": "2e8f3425-cc80-4dde-e19a-ace4d40154c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Criterion: 0.02771651236316883\n",
      "Stop Criterion: 0.017384501214288788\n",
      "Stop Criterion: 0.004953136813105215\n",
      "Stop Criterion: 0.0012521199148616802\n",
      "Stop Criterion: 0.0002414259085647203\n",
      "Stop Criterion: 3.704678373148938e-05\n",
      "Stop Criterion: 7.225579794613062e-06\n",
      "Stop Criterion: 2.2373322264342416e-06\n",
      "Stop Criterion: 8.001266062565949e-07\n",
      "Stop Criterion: 3.0496679119347266e-07\n",
      "Stop Criterion: 1.2169189011155522e-07\n",
      "Stop Criterion: 5.02008332645738e-08\n",
      "[1, 0, 0]\n",
      "tf.Tensor(\n",
      "[[ 0.79596435  0.          0.        ]\n",
      " [ 0.4636718   0.          0.        ]\n",
      " [-0.24470637  0.          0.        ]], shape=(3, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# test sample\n",
    "Data=np.array([[7,1,2],[5,2,4],[0,3,6]], np.float64)\n",
    "n1,n2=np.shape(Data)\n",
    "lam=1.3 #1/np.sqrt(n1)\n",
    "th=0.0000001\n",
    "rho=1.5\n",
    "mup=1.25\n",
    "H=OP_main(Data,lam,th,rho,mup)\n",
    "print(H.Elabel)\n",
    "print(H.FE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OP model with GST\n",
    "from tensorflow.python.ops.linalg_ops import norm_v2\n",
    "class OPGST_main():\n",
    "    \n",
    "    def __init__(self, Data, lam=1/np.sqrt(n1),th=0.000000000000001, rho=1.5, mup=1.25,p=1):\n",
    "        \n",
    "        #(Data, lam,th, rho, mup)=value_sets\n",
    "\n",
    "        self.p=p\n",
    "        n1,n2=np.shape(Data)\n",
    "        self.lam=lam #1/np.sqrt(n1)\n",
    "        self.eps=0.000000000000001\n",
    "        self.d_nrom=norm_v2(Data)\n",
    "        norm_two=np.linalg.svd(Data,compute_uv=False)[0]#norm_v2(Data,2)\n",
    "        #print(norm_two)\n",
    "        norm_inf=norm_v2(Data,np.inf)/self.lam\n",
    "        #print(norm_inf)\n",
    "        dual_norm=np.max([norm_two, norm_inf])\n",
    "        Lambda_int=Data/dual_norm\n",
    "        #print(Lambda_int[0,0]) \n",
    "        self.mu=mup/norm_two #1.25\n",
    "        self.maxmu=self.mu*10**(7)\n",
    "        self.rho=rho #1.5\n",
    "        self.stages=200 \n",
    "        self.tol=10**(-7) \n",
    "        \n",
    "        X_int, E_int= tf.zeros([n1,n2], tf.float64), tf.zeros([n1,n2], tf.float64)\n",
    "        value_sets=(Data, X_int, E_int, Lambda_int)\n",
    "        self.FX, self.FE = self.OP_ADMM_main(value_sets) \n",
    "        self.Elabel=self.getLable(self.FE,th)\n",
    " \n",
    "    def OP_ADMM_main(self, inputs):\n",
    "        (Data, X_int, E_int, Lambda_int) = inputs  \n",
    "        self.X,self.E,self.Lambda  = [],[],[]  \n",
    "        self.E.append(self.Updata_E(Data, X_int, Lambda_int))  \n",
    "        self.X.append(self.Updata_X(Data, self.E[-1], Lambda_int))      \n",
    "        self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], Lambda_int))  \n",
    "        self.mu=np.min([self.mu*self.rho, self.maxmu])\n",
    "        #print(self.E[-1][0,0])\n",
    "        #print(self.X[-1][0,0])  \n",
    "        #print(self.Lambda[-1][0,0])  \n",
    "        for stage in range(1,self.stages): \n",
    "            self.E.append(self.Updata_E(Data, self.X[-1], self.Lambda[-1]))  \n",
    "            self.X.append(self.Updata_X(Data, self.E[-1], self.Lambda[-1]))      \n",
    "            self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], self.Lambda[-1]))   \n",
    "            self.mu=np.min([self.mu*self.rho, self.maxmu]) \n",
    "            stopCriterion= norm_v2(Data-self.X[-1]-self.E[-1])/self.d_nrom \n",
    "            print(\"Stop Criterion: {}\".format(stopCriterion))\n",
    "            #print(self.E[-1][0,0])\n",
    "            #print(self.X[-1][0,0]) \n",
    "            #print(self.Lambda[-1][0,0])\n",
    "            if stopCriterion < self.tol:\n",
    "                break \n",
    "        return self.X[-1], self.E[-1]   \n",
    "     \n",
    "\n",
    "     \n",
    "\n",
    "    def Updata_X(self,Data, E, Lambda):#需要修改\n",
    "      \n",
    "        temp=-E+Data+Lambda/self.mu  \n",
    "        return self.SVT(temp,1/self.mu)\n",
    "\n",
    " \n",
    "   \n",
    "    def SVT(self,X,th):\n",
    "        n1, n2= np.shape(X)\n",
    "        rank=np.min([n1,n2])  \n",
    "        U_int, S_int, VT_int=np.linalg.svd(X, full_matrices=True, compute_uv=True, hermitian=False)\n",
    "        S_int=self.Generalized_Soft_Thresholding(S_int,th,self.p)\n",
    "        rank=len(np.where(S_int > self.eps)[0])\n",
    "        if rank==0:\n",
    "            rank=1  \n",
    "        S_int=tf.compat.v1.matrix_diag(S_int) \n",
    "        Ak_int=tf.matmul(tf.matmul(U_int[:,0:rank],S_int[0:rank,0:rank]),VT_int[0:rank,:]) \n",
    "          \n",
    "        return Ak_int    \n",
    " \n",
    "    def Updata_E(self, Data, X, Lambda):\n",
    "        \n",
    "        Temp= Data-X+Lambda/self.mu\n",
    "        return self.sparse_col(  Temp, self.lam/self.mu)\n",
    " \n",
    "\n",
    "   \n",
    "\n",
    "    def sparse_col(self, E, tau): \n",
    "        result=[]\n",
    "        n1,n2=np.shape(E)\n",
    "        for i in range(n2):\n",
    "            result.append(self.Generalized_Soft_Thresholding(tf.norm(E[:,i]),tau,self.p)*E[:,i]/(tf.norm(E[:,i])+self.eps)) \n",
    "        return tf.transpose(result,[1,0])\n",
    "\n",
    "  \n",
    "     \n",
    "\n",
    "    def Updata_Lambda(self, Data, X, E, Lambda):\n",
    "        Lambda= Lambda+tf.multiply(self.mu, Data-X-E)\n",
    "        return Lambda\n",
    " \n",
    "\n",
    "    def getLable(self, E,th): \n",
    "        Elabel=[]\n",
    "        n1,n2=np.shape(E)\n",
    "        for i in range(n2):\n",
    "            if tf.norm(E[:,i])>th:\n",
    "                Elabel.append(1)\n",
    "            else:\n",
    "                Elabel.append(0)\n",
    "        return Elabel\n",
    "         \n",
    "        \n",
    "    def Generalized_Soft_Thresholding(self,S,weight,p):\n",
    "        #diagS: a vector\n",
    "        #weight: a value\n",
    "        if np.shape(S) == ():\n",
    "            diagS=[S]\n",
    "        else:\n",
    "            diagS=S#np.array(diagS,np.float64)\n",
    "        J=5 \n",
    "        sigma0   =    np.abs(diagS)\n",
    "        tau_GST  =   (2*weight*(1-p))**(1/(2-p))   +   p*weight*(2*(1-p)*weight)**((p-1)/(2-p)) \n",
    "        Delta=[];\n",
    "        for i in range(len(diagS)):\n",
    "                if sigma0[i]>tau_GST: \n",
    "                    delta=sigma0[i]  \n",
    "                    for k in range(J): \n",
    "                            delta=sigma0[i]-weight*p*delta**(p-1)           \n",
    "                            k=k+1  \n",
    "                    Delta.append(np.sign(diagS[i])*delta)  \n",
    "                else:\n",
    "                    Delta.append(0) \n",
    "        if np.shape(S) == ():\n",
    "            return np.array(Delta[0],np.float64) \n",
    "        else:\n",
    "            return np.array(Delta,np.float64) \n",
    "\n",
    "\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Criterion: 0.06968655348307115\n",
      "Stop Criterion: 0.033549524337254284\n",
      "Stop Criterion: 0.014605080229469644\n",
      "Stop Criterion: 0.0064766240023816065\n",
      "Stop Criterion: 0.003569636981640282\n",
      "Stop Criterion: 0.0013102399929058853\n",
      "Stop Criterion: 0.00015949477959337335\n",
      "Stop Criterion: 4.1360014467796234e-05\n",
      "Stop Criterion: 1.8868610062230848e-05\n",
      "Stop Criterion: 5.632345409268264e-06\n",
      "Stop Criterion: 2.2922222900111563e-06\n",
      "Stop Criterion: 1.0333381822169081e-06\n",
      "Stop Criterion: 4.706433338958856e-07\n",
      "Stop Criterion: 2.0817622293720724e-07\n",
      "Stop Criterion: 9.149778874305399e-08\n",
      "[1, 0, 0]\n",
      "tf.Tensor(\n",
      "[[ 6.38093858 -0.          0.        ]\n",
      " [ 3.76187763  0.          0.        ]\n",
      " [-1.85718315  0.          0.        ]], shape=(3, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# test sample\n",
    "Data=np.array([[7,1,2],[5,2,4],[0,3,6]], np.float64)\n",
    "n1,n2=np.shape(Data)\n",
    "lam=1.1 #1/np.sqrt(n1)\n",
    "th=0.0000001\n",
    "rho=1.5\n",
    "mup=1.25\n",
    "p=0.8\n",
    "#value_sets=(Data,lam,th,rho,mup,p)\n",
    "HGST=OPGST_main(Data,lam,th,rho,mup,p)\n",
    "print(HGST.Elabel)\n",
    "print(HGST.FE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OP model with ETP\n",
    "from tensorflow.python.ops.linalg_ops import norm_v2\n",
    "class OPETP_main():\n",
    "    \n",
    "    def __init__(self, Data, lam=1/np.sqrt(n1),th=0.000000000000001, rho=1.5, mup=1.25,p=1,Maxiter=1000,tol=10**(-7)):\n",
    "        \n",
    "        #(Data, lam,th, rho, mup)=value_sets\n",
    "\n",
    "        self.p=p\n",
    "        n1,n2=np.shape(Data)\n",
    "        self.lam=lam #1/np.sqrt(n1)\n",
    "        self.eps=0.000000000000001\n",
    "        self.d_nrom=norm_v2(Data)\n",
    "        norm_two=np.linalg.svd(Data,compute_uv=False)[0]#norm_v2(Data,2)\n",
    "        #print(norm_two)\n",
    "        norm_inf=norm_v2(Data,np.inf)/self.lam\n",
    "        #print(norm_inf)\n",
    "        dual_norm=np.max([norm_two, norm_inf])\n",
    "        Lambda_int=Data/dual_norm\n",
    "        #print(Lambda_int[0,0]) \n",
    "        self.mu=mup/norm_two #1.25\n",
    "        self.maxmu=self.mu*10**(7)\n",
    "        self.rho=rho #1.5\n",
    "        self.stages=200\n",
    "        self.tol=10**(-7) \n",
    "        \n",
    "        X_int, E_int= tf.zeros([n1,n2], tf.float64), tf.zeros([n1,n2], tf.float64)\n",
    "        value_sets=(Data, X_int, E_int, Lambda_int)\n",
    "        self.FX, self.FE = self.OP_ADMM_main(value_sets) \n",
    "        self.Elabel=self.getLable(self.FE,th)\n",
    " \n",
    "    def OP_ADMM_main(self, inputs):\n",
    "        (Data, X_int, E_int, Lambda_int) = inputs  \n",
    "        self.X,self.E,self.Lambda  = [],[],[]  \n",
    "        self.E.append(self.Updata_E(Data, X_int, Lambda_int))  \n",
    "        self.X.append(self.Updata_X(Data, self.E[-1], Lambda_int))      \n",
    "        self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], Lambda_int))  \n",
    "        self.mu=np.min([self.mu*self.rho, self.maxmu])\n",
    "        #print(self.E[-1][0,0])\n",
    "        #print(self.X[-1][0,0])  \n",
    "        #print(self.Lambda[-1][0,0])  \n",
    "        for stage in range(1,self.stages): \n",
    "            self.E.append(self.Updata_E(Data, self.X[-1], self.Lambda[-1]))  \n",
    "            self.X.append(self.Updata_X(Data, self.E[-1], self.Lambda[-1]))      \n",
    "            self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], self.Lambda[-1]))   \n",
    "            self.mu=np.min([self.mu*self.rho, self.maxmu]) \n",
    "            stopCriterion= norm_v2(Data-self.X[-1]-self.E[-1])/self.d_nrom \n",
    "            print(\"Stop Criterion: {}\".format(stopCriterion))\n",
    "            #print(self.E[-1][0,0])\n",
    "           # print(self.X[-1][0,0]) \n",
    "            #print(self.Lambda[-1][0,0])\n",
    "            if stopCriterion < self.tol:\n",
    "                break \n",
    "        return self.X[-1], self.E[-1]   \n",
    "     \n",
    "\n",
    "     \n",
    "\n",
    "    def Updata_X(self,Data, E, Lambda): \n",
    "      \n",
    "        temp=-E+Data+Lambda/self.mu  \n",
    "        return self.SVT(temp,1/self.mu)\n",
    "\n",
    " \n",
    "   \n",
    "    def SVT(self,X,th):\n",
    "        n1, n2= np.shape(X)\n",
    "        rank=np.min([n1,n2])  \n",
    "        U_int, S_int, VT_int=np.linalg.svd(X, full_matrices=True, compute_uv=True, hermitian=False)\n",
    "        S_int=self.GAI_ETP(S_int,th,self.p)\n",
    "        rank=len(np.where(S_int > self.eps)[0])\n",
    "        if rank==0:\n",
    "            rank=1  \n",
    "        S_int=tf.compat.v1.matrix_diag(S_int) \n",
    "        Ak_int=tf.matmul(tf.matmul(U_int[:,0:rank],S_int[0:rank,0:rank]),VT_int[0:rank,:]) \n",
    "          \n",
    "        return Ak_int    \n",
    " \n",
    "    def Updata_E(self, Data, X, Lambda): \n",
    "        Temp= Data-X+Lambda/self.mu \n",
    "        return self.sparse_col(  Temp, self.lam/self.mu)\n",
    " \n",
    "\n",
    "   \n",
    "\n",
    "    def sparse_col(self, E, tau): \n",
    "        result=[]\n",
    "        n1,n2=np.shape(E)\n",
    "        for i in range(n2):\n",
    "            result.append(self.GAI_ETP(tf.norm(E[:,i]),tau,self.p)*E[:,i]/(tf.norm(E[:,i])+self.eps)) \n",
    "        return tf.transpose(result,[1,0])\n",
    "\n",
    "  \n",
    "     \n",
    "\n",
    "    def Updata_Lambda(self, Data, X, E, Lambda):\n",
    "        Lambda= Lambda+tf.multiply(self.mu, Data-X-E)\n",
    "        return Lambda\n",
    " \n",
    "\n",
    "    def getLable(self, E,th): \n",
    "        Elabel=[]\n",
    "        n1,n2=np.shape(E)\n",
    "        for i in range(n2):\n",
    "            if tf.norm(E[:,i])>th:\n",
    "                Elabel.append(1)\n",
    "            else:\n",
    "                Elabel.append(0)\n",
    "        return Elabel\n",
    "         \n",
    "        \n",
    "   \n",
    "\n",
    "    def GAI_ETP(self,xi,lambd,gamma,Iter=10,tol=10**(-6)):\n",
    "        #Iter=10; \n",
    "        a0=np.max([np.log((1-np.exp(-gamma))/(lambd*gamma**2))/(-gamma),0])\n",
    "        #print(a0)\n",
    "        delta=a0+self.ETP_gradient(a0,gamma,lambd)\n",
    "        #print(delta) \n",
    "        if np.shape(xi) == ():\n",
    "            x=[xi]\n",
    "        else:\n",
    "            x=xi\n",
    "        n=len(x)\n",
    "        y=[]\n",
    " \n",
    "\n",
    "     \n",
    "        for j in range(n):\n",
    "            gradient_g= self.ETP_gradient(x[j],gamma,lambd)\n",
    "            if gradient_g==0:\n",
    "                BARx_b=x[j] \n",
    "            else:\n",
    "                if delta<x[j]:\n",
    "                    a=x[j]\n",
    "                    sto=0\n",
    "                    kkk=0\n",
    "                    while sto==0:\n",
    "                        kkk=kkk+1\n",
    "                        a1=x[j]-self.ETP_gradient(a,gamma,lambd)\n",
    "                        a2=x[j]-self.ETP_gradient(a1,gamma,lambd) \n",
    "                        if np.abs(a2-2*a1+a)<tol or kkk>=Iter:\n",
    "                            if np.abs(a2-2*a1+a)<self.eps:\n",
    "                                BARx_b=a2\n",
    "                            else:\n",
    "                                BARx_b=a1-(a2-a1)*(a1-a)/(a2-2*a1+a)\n",
    "                            break\n",
    "                        a=a1-(a2-a1)*(a1-a)/(a2-2*a1+a) \n",
    "                        #print(a)\n",
    "                else:\n",
    "                    BARx_b=a0\n",
    "            if self.ETP_fun(BARx_b,x[j],gamma,lambd)<=self.ETP_fun(0,x[j],gamma,lambd):\n",
    "                y.append(BARx_b)   \n",
    "            else:\n",
    "                y.append(0)\n",
    "                    \n",
    "        if np.shape(xi) == ():\n",
    "            return np.array(y[0],np.float64) \n",
    "        else:\n",
    "            return np.array(y,np.float64)\n",
    "      \n",
    "           \n",
    "    #ETP's gradient \n",
    "    def ETP_gradient(self,x,gamma,lambd):\n",
    "        gradient_g=gamma*lambd*np.exp(-gamma*x)/(1-np.exp(-gamma)) \n",
    "        return gradient_g\n",
    " \n",
    "    def ETP_fun(self,x,y,gamma,lambd):\n",
    "        g=1/2*(y-x)**2+lambd*(1-np.exp(-gamma*x))/(1-np.exp(-gamma))\n",
    "        return g   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Criterion: 2.4261219471294536e-16\n",
      "[1, 0, 0]\n",
      "tf.Tensor(\n",
      "[[ 7.00000000e+00 -0.00000000e+00  0.00000000e+00]\n",
      " [ 5.00000000e+00 -0.00000000e+00  0.00000000e+00]\n",
      " [-5.92118946e-15 -0.00000000e+00  0.00000000e+00]], shape=(3, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# test sample\n",
    "Data=np.array([[7,1,2],[5,2,4],[0,3,6]], np.float64)\n",
    "n1,n2=np.shape(Data)\n",
    "lam=6#1/np.sqrt(n1)\n",
    "th=0.0000001\n",
    "rho=1.5\n",
    "mup=1.25\n",
    "p=10\n",
    "#value_sets=(Data,lam,th,rho,mup,p)\n",
    "HETP=OPETP_main(Data,lam,th,rho,mup,p)\n",
    "print(HETP.Elabel)\n",
    "print(HETP.FE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps=0.000000000000001\n",
    "# def sparse_col(E, tau,p): \n",
    "#         result=[]\n",
    "#         n1,n2=np.shape(E)\n",
    "#         for i in range(n2):\n",
    "#             print(tf.norm(E[:,i]))\n",
    "#             print(GAI_ETP(tf.norm(E[:,i]),tau,p))\n",
    "#             result.append(GAI_ETP(tf.norm(E[:,i]),tau,p)*E[:,i]/(tf.norm(E[:,i])+eps)) \n",
    "#         return tf.transpose(result,[1,0])\n",
    "\n",
    "# def GAI_ETP(xi,lambd,gamma,Iter=10,tol=10**(-6)):\n",
    "#         #Iter=10; \n",
    "#         a0=np.max([np.log((1-np.exp(-gamma))/(lambd*gamma**2))/(-gamma),0])\n",
    "#         #print(a0)\n",
    "#         delta=a0+ETP_gradient(a0,gamma,lambd)\n",
    "#         #print(delta) \n",
    "#         if np.shape(xi) == ():\n",
    "#             x=[xi]\n",
    "#         else:\n",
    "#             x=xi\n",
    "#         n=len(x)\n",
    "#         y=[]\n",
    " \n",
    "\n",
    "     \n",
    "#         for j in range(n):\n",
    "#             gradient_g= ETP_gradient(x[j],gamma,lambd)\n",
    "#             if gradient_g==0:\n",
    "#                 BARx_b=x[j] \n",
    "#             else:\n",
    "#                 if delta<x[j]:\n",
    "#                     a=x[j]\n",
    "#                     sto=0\n",
    "#                     kkk=0\n",
    "#                     while sto==0:\n",
    "#                         kkk=kkk+1\n",
    "#                         a1=x[j]-ETP_gradient(a,gamma,lambd)\n",
    "#                         a2=x[j]-ETP_gradient(a1,gamma,lambd) \n",
    "#                         if np.abs(a2-2*a1+a)<tol or kkk>=Iter:\n",
    "#                             if a2-2*a1+a<eps:\n",
    "#                                 BARx_b=a2\n",
    "#                             else:\n",
    "#                                 BARx_b=a1-(a2-a1)*(a1-a)/(a2-2*a1+a)\n",
    "#                             break\n",
    "#                         a=a1-(a2-a1)*(a1-a)/(a2-2*a1+a) \n",
    "#                         #print(a)\n",
    "#                 else:\n",
    "#                     BARx_b=a0\n",
    "#             if ETP_fun(BARx_b,x[j],gamma,lambd)<=ETP_fun(0,x[j],gamma,lambd):\n",
    "#                 y.append(BARx_b)   \n",
    "#             else:\n",
    "#                 y.append(0)\n",
    "                    \n",
    "#         if np.shape(xi) == ():\n",
    "#             return np.array(y[0],np.float64) \n",
    "#         else:\n",
    "#             return np.array(y,np.float64)\n",
    "      \n",
    "           \n",
    "#     #ETP's gradient \n",
    "# def ETP_gradient(x,gamma,lambd):\n",
    "#     gradient_g=gamma*lambd*np.exp(-gamma*x)/(1-np.exp(-gamma)) \n",
    "#     return gradient_g\n",
    " \n",
    "# def ETP_fun(x,y,gamma,lambd):\n",
    "#     g=1/2*(y-x)**2+lambd*(1-np.exp(-gamma*x))/(1-np.exp(-gamma))\n",
    "#     return g   \n",
    "\n",
    "# print(sparse_col(np.array([[12.6,3.6,5.4],[9.0,9.0,10.8],[0,14.4,16.2]],np.float64),13.7196,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OP Model with LOG\n",
    "from tensorflow.python.ops.linalg_ops import norm_v2\n",
    "class OPLOG_main():\n",
    "    \n",
    "    def __init__(self, Data, lam=1/np.sqrt(n1),th=0.000000000000001, rho=1.5, mup=1.25,p=1,Maxiter=1000,tol=10**(-7) ):\n",
    "        \n",
    "        #(Data, lam,th, rho, mup)=value_sets\n",
    "\n",
    "        self.p=p\n",
    "        n1,n2=np.shape(Data)\n",
    "        self.lam=lam #1/np.sqrt(n1)\n",
    "        self.eps=0.000000000000001\n",
    "        self.d_nrom=norm_v2(Data)\n",
    "        norm_two=np.linalg.svd(Data,compute_uv=False)[0]#norm_v2(Data,2)\n",
    "        #print(norm_two)\n",
    "        norm_inf=norm_v2(Data,np.inf)/self.lam\n",
    "        #print(norm_inf)\n",
    "        dual_norm=np.max([norm_two, norm_inf])\n",
    "        Lambda_int=Data/dual_norm\n",
    "        #print(Lambda_int[0,0]) \n",
    "        self.mu=mup/norm_two #1.25\n",
    "        self.maxmu=self.mu*10**(7)\n",
    "        self.rho=rho #1.5\n",
    "        self.stages=Maxiter\n",
    "        self.tol=tol\n",
    "        \n",
    "        X_int, E_int= tf.zeros([n1,n2], tf.float64), tf.zeros([n1,n2], tf.float64)\n",
    "        value_sets=(Data, X_int, E_int, Lambda_int)\n",
    "        self.FX, self.FE = self.OP_ADMM_main(value_sets) \n",
    "        self.Elabel=self.getLable(self.FE,th)\n",
    " \n",
    "    def OP_ADMM_main(self, inputs):\n",
    "        (Data, X_int, E_int, Lambda_int) = inputs  \n",
    "        self.X,self.E,self.Lambda  = [],[],[]  \n",
    "        self.E.append(self.Updata_E(Data, X_int, Lambda_int))  \n",
    "        self.X.append(self.Updata_X(Data, self.E[-1], Lambda_int))      \n",
    "        self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], Lambda_int))  \n",
    "        self.mu=np.min([self.mu*self.rho, self.maxmu])\n",
    "        #print(self.E[-1][0,0])\n",
    "        #print(self.X[-1][0,0])  \n",
    "        #print(self.Lambda[-1][0,0])  \n",
    "        for stage in range(1,self.stages): \n",
    "            self.E.append(self.Updata_E(Data, self.X[-1], self.Lambda[-1]))  \n",
    "            self.X.append(self.Updata_X(Data, self.E[-1], self.Lambda[-1]))      \n",
    "            self.Lambda.append(self.Updata_Lambda(Data, self.X[-1], self.E[-1], self.Lambda[-1]))   \n",
    "            self.mu=np.min([self.mu*self.rho, self.maxmu]) \n",
    "            stopCriterion= norm_v2(Data-self.X[-1]-self.E[-1])/self.d_nrom \n",
    "            print(\"Stop Criterion: {}\".format(stopCriterion))\n",
    "            #print(self.E[-1][0,0])\n",
    "            #print(self.X[-1][0,0]) \n",
    "            #print(self.Lambda[-1][0,0])\n",
    "            if stopCriterion < self.tol:\n",
    "                break \n",
    "        return self.X[-1], self.E[-1]   \n",
    "     \n",
    "\n",
    "     \n",
    "\n",
    "    def Updata_X(self,Data, E, Lambda): \n",
    "        temp=-E+Data+Lambda/self.mu  \n",
    "        return self.SVT(temp,1/self.mu)\n",
    "\n",
    " \n",
    "   \n",
    "    def SVT(self,X,th):\n",
    "        n1, n2= np.shape(X)\n",
    "        rank=np.min([n1,n2])  \n",
    "        U_int, S_int, VT_int=np.linalg.svd(X, full_matrices=True, compute_uv=True, hermitian=False)\n",
    "        S_int=self.GAI_LOG(S_int,th,self.p)\n",
    "        rank=len(np.where(S_int > self.eps)[0])\n",
    "        if rank==0:\n",
    "            rank=1  \n",
    "        S_int=tf.compat.v1.matrix_diag(S_int) \n",
    "        Ak_int=tf.matmul(tf.matmul(U_int[:,0:rank],S_int[0:rank,0:rank]),VT_int[0:rank,:]) \n",
    "          \n",
    "        return Ak_int    \n",
    " \n",
    "    def Updata_E(self, Data, X, Lambda):\n",
    "        \n",
    "        Temp= Data-X+Lambda/self.mu\n",
    "        return self.sparse_col(  Temp, self.lam/self.mu)\n",
    " \n",
    "\n",
    "   \n",
    "\n",
    "    def sparse_col(self, E, tau): \n",
    "        result=[]\n",
    "        n1,n2=np.shape(E)\n",
    "        for i in range(n2):\n",
    "            result.append(self.GAI_LOG(tf.norm(E[:,i]),tau,self.p)*E[:,i]/(tf.norm(E[:,i])+self.eps)) \n",
    "        return tf.transpose(result,[1,0])\n",
    "\n",
    "  \n",
    "     \n",
    "\n",
    "    def Updata_Lambda(self, Data, X, E, Lambda):\n",
    "        Lambda= Lambda+tf.multiply(self.mu, Data-X-E)\n",
    "        return Lambda\n",
    " \n",
    "\n",
    "    def getLable(self, E,th): \n",
    "        Elabel=[]\n",
    "        n1,n2=np.shape(E)\n",
    "        for i in range(n2):\n",
    "            if tf.norm(E[:,i])>th:\n",
    "                Elabel.append(1)\n",
    "            else:\n",
    "                Elabel.append(0)\n",
    "        return Elabel\n",
    "         \n",
    "\n",
    "    def LOG_th(self,x,tau,lambd):\n",
    "        x0=np.sqrt(2*lambd)-tau\n",
    "        y=np.sign(np.max([x-x0,0]))*(1/2)*((x-tau)+np.sqrt((x+tau)**2-2*lambd))+np.sign(np.max([-x0-x,0]))*(1/2)*((x+tau)+np.sqrt((x-tau)**2-2*lambd))\n",
    "        return y\n",
    "    \n",
    "    \n",
    "    \n",
    "    def GAI_LOG(self,xi,lambd,gamma,Iter=10,tol=10**(-4)):\n",
    "        #Iter=10; \n",
    "    \n",
    "        a0=np.max([np.sqrt(lambd)-gamma,0])\n",
    "        #print(a0)\n",
    "        delta=a0+self.LOG_gradient(a0,gamma,lambd)\n",
    "        #print(delta) \n",
    "        if np.shape(xi) == ():\n",
    "            x=[xi]\n",
    "        else:\n",
    "            x=xi\n",
    "        n=len(x)\n",
    "        y=[] \n",
    "     \n",
    "        for j in range(n):\n",
    "            gradient_g= self.LOG_gradient(x[j],gamma,lambd)\n",
    "            if gradient_g==0:\n",
    "                BARx_b=x[j] \n",
    "            else:\n",
    "                if delta<x[j]:\n",
    "                    a=x[j]\n",
    "                    sto=0\n",
    "                    kkk=0\n",
    "                    while sto==0:\n",
    "                        kkk=kkk+1\n",
    "                        a1=x[j]-self.LOG_gradient(a,gamma,lambd)\n",
    "                        a2=x[j]-self.LOG_gradient(a1,gamma,lambd) \n",
    "                        if np.abs(a2-2*a1+a)<tol or kkk>=Iter:\n",
    "                            if np.abs(a2-2*a1+a)<self.eps:\n",
    "                                BARx_b=a2\n",
    "                            else:\n",
    "                                BARx_b=a1-(a2-a1)*(a1-a)/(a2-2*a1+a)\n",
    "                            break\n",
    "                        a=a1-(a2-a1)*(a1-a)/(a2-2*a1+a) \n",
    "                        #print(a)\n",
    "                else:\n",
    "                    BARx_b=a0\n",
    "                if self.LOG_fun(BARx_b,x[j],gamma,lambd)<=self.LOG_fun(0,x[j],gamma,lambd):\n",
    "                    y.append(BARx_b)   \n",
    "                else:\n",
    "                    y.append(0)\n",
    "        \n",
    "        if np.shape(xi) == ():\n",
    "            return np.array(y[0],np.float64) \n",
    "        else:\n",
    "            return np.array(y,np.float64)\n",
    "      \n",
    "           \n",
    "\n",
    "\n",
    "#LOG's gradient \n",
    "    def LOG_gradient(self,x,gamma,lambd):\n",
    "        gradient_g=lambd/(gamma+x)\n",
    "        return gradient_g\n",
    " \n",
    "    def LOG_fun(self,x,y,gamma,lambd):\n",
    "        g=1/2*(y-x)**2+lambd*(np.log(gamma+x))\n",
    "        return g\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Criterion: 0.0026366742250366285\n",
      "Stop Criterion: 0.0016644579340530348\n",
      "Stop Criterion: 0.000599125718678935\n",
      "Stop Criterion: 0.0002322995954917029\n",
      "Stop Criterion: 9.510577059916805e-05\n",
      "Stop Criterion: 4.023698178748473e-05\n",
      "Stop Criterion: 1.736866056257894e-05\n",
      "Stop Criterion: 7.594570802103793e-06\n",
      "Stop Criterion: 3.351016147898213e-06\n",
      "Stop Criterion: 1.4909650435274126e-06\n",
      "Stop Criterion: 4.1122749716615434e-07\n",
      "Stop Criterion: 1.6144436485787669e-07\n",
      "Stop Criterion: 7.165158124760496e-08\n",
      "[1, 0, 0]\n",
      "tf.Tensor(\n",
      "[[ 1.51067052 -0.         -0.        ]\n",
      " [ 1.03186057  0.          0.        ]\n",
      " [-0.11010954  0.          0.        ]], shape=(3, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# test sample\n",
    "Data=np.array([[7,1,2],[5,2,4],[0,3,6]], np.float64)\n",
    "n1,n2=np.shape(Data)\n",
    "lam=9#1/np.sqrt(n1)\n",
    "th=0.0000001\n",
    "rho=1.5\n",
    "mup=1.25\n",
    "p=23\n",
    "#value_sets=(Data,lam,th,rho,mup,p)\n",
    "HLOG=OPLOG_main(Data,lam,th,rho,mup,p)\n",
    "print(HLOG.Elabel)\n",
    "print(HLOG.FE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps=0.000000000000001\n",
    "# def sparse_col(E, tau,p): \n",
    "#         result=[]\n",
    "#         n1,n2=np.shape(E)\n",
    "#         for i in range(n2):\n",
    "#             result.append(GAI_LOG(tf.norm(E[:,i]),tau,p)*E[:,i]/(tf.norm(E[:,i])+eps)) \n",
    "#             print(E[:,i])\n",
    "#             print((tf.norm(E[:,i]))\n",
    "#         return tf.transpose(result,[1,0])\n",
    "    \n",
    "    \n",
    "# def GAI_LOG(xi,lambd,gamma,Iter=10,tol=10**(-4)):\n",
    "#         #Iter=10; \n",
    "    \n",
    "#         a0=np.max([np.sqrt(lambd)-gamma,0])\n",
    "#         #print(a0)\n",
    "#         delta=a0+LOG_gradient(a0,gamma,lambd)\n",
    "#         #print(delta) \n",
    "#         if np.shape(xi) == ():\n",
    "#             x=[xi]\n",
    "#         else:\n",
    "#             x=xi\n",
    "#         n=len(x)\n",
    "#         y=[]\n",
    " \n",
    "\n",
    "     \n",
    "#         for j in range(n):\n",
    "#             gradient_g= LOG_gradient(x[j],gamma,lambd)\n",
    "#             if gradient_g==0:\n",
    "#                 BARx_b=x[j] \n",
    "#             else:\n",
    "#                 if delta<x[j]:\n",
    "#                     a=x[j]\n",
    "#                     sto=0\n",
    "#                     kkk=0\n",
    "#                     while sto==0:\n",
    "#                         kkk=kkk+1\n",
    "#                         a1=x[j]-LOG_gradient(a,gamma,lambd)\n",
    "#                         a2=x[j]-LOG_gradient(a1,gamma,lambd) \n",
    "#                         if np.abs(a2-2*a1+a)<tol or kkk>=Iter:\n",
    "#                             BARx_b=a1-(a2-a1)*(a1-a)/(a2-2*a1+a)\n",
    "#                             break\n",
    "#                         a=a1-(a2-a1)*(a1-a)/(a2-2*a1+a) \n",
    "#                         #print(a)\n",
    "#                 else:\n",
    "#                     BARx_b=a0\n",
    "#             if LOG_fun(BARx_b,x[j],gamma,lambd)<=LOG_fun(0,x[j],gamma,lambd):\n",
    "#                  y.append(BARx_b)   \n",
    "#             else:\n",
    "#                  y.append(0)\n",
    "        \n",
    "#         if np.shape(xi) == ():\n",
    "#             return np.array(y[0],np.float64) \n",
    "#         else:\n",
    "#             return np.array(y,np.float64)\n",
    "      \n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #LOG's gradient \n",
    "# def LOG_gradient(x,gamma,lambd):\n",
    "#         gradient_g=lambd/(gamma+x)\n",
    "#         return gradient_g\n",
    "    \n",
    "# def LOG_fun(x,y,gamma,lambd):\n",
    "#         g=1/2*(y-x)**2+lambd*(np.log(gamma+x))\n",
    "#         return g\n",
    "\n",
    "# print(sparse_col(np.array([[7],[5],[0]],np.float64),34,56))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Credit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "0wI9XxRlxHaR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1;1;18;4;2;1049;1;2;4;2;1;4;2;21;3;1;1;3;1;1;1\n",
      "1        1;1;9;4;0;2799;1;3;2;3;1;2;1;36;3;1;2;3;2;1;1\n",
      "2        1;2;12;2;9;841;2;4;2;2;1;4;1;23;3;1;1;2;1;1;1\n",
      "3       1;1;12;4;0;2122;1;3;3;3;1;2;1;39;3;1;2;2;2;1;2\n",
      "4       1;1;12;4;0;2171;1;3;4;3;1;4;2;38;1;2;2;2;1;1;2\n",
      "                            ...                       \n",
      "995     0;1;24;2;3;1987;1;3;2;3;1;4;1;21;3;1;1;2;2;1;1\n",
      "996     0;1;24;2;0;2303;1;5;4;3;2;1;1;45;3;2;1;3;1;1;1\n",
      "997    0;4;21;4;0;12680;5;5;4;3;1;4;4;30;3;3;1;4;1;2;1\n",
      "998     0;2;12;2;3;6468;5;1;2;3;1;1;4;52;3;2;1;4;1;2;1\n",
      "999     0;1;30;2;2;6350;5;5;4;3;1;4;2;31;3;2;1;3;1;1;1\n",
      "Name: Creditability;Account_Balance;Duration_of_Credit_monthly;Payment_Status_of_Previous_Credit;Purpose;Credit_Amount;Value_Savings_Stocks;Length_of_current_employment;Instalment_per_cent;Sex_Marital_Status;Guarantors;Duration_in_Current_address;Most_valuable_available_asset;Age_years;Concurrent_Credits;Type_of_apartment;No_of_Credits_at_this_Bank;Occupation;No_of_dependents;Telephone;Foreign_Worker, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#loading data Geman  \n",
    "df = pd.read_csv('german.csv')\n",
    "df.tail(3)\n",
    "print(df['Creditability;Account_Balance;Duration_of_Credit_monthly;Payment_Status_of_Previous_Credit;Purpose;Credit_Amount;Value_Savings_Stocks;Length_of_current_employment;Instalment_per_cent;Sex_Marital_Status;Guarantors;Duration_in_Current_address;Most_valuable_available_asset;Age_years;Concurrent_Credits;Type_of_apartment;No_of_Credits_at_this_Bank;Occupation;No_of_dependents;Telephone;Foreign_Worker'])\n",
    "name='Creditability;Account_Balance;Duration_of_Credit_monthly;Payment_Status_of_Previous_Credit;Purpose;Credit_Amount;Value_Savings_Stocks;Length_of_current_employment;Instalment_per_cent;Sex_Marital_Status;Guarantors;Duration_in_Current_address;Most_valuable_available_asset;Age_years;Concurrent_Credits;Type_of_apartment;No_of_Credits_at_this_Bank;Occupation;No_of_dependents;Telephone;Foreign_Worker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creditability;Account_Balance;Duration_of_Credit_monthly;Payment_Status_of_Previous_Credit;Purpose;Credit_Amount;Value_Savings_Stocks;Length_of_current_employment;Instalment_per_cent;Sex_Marital_Status;Guarantors;Duration_in_Current_address;Most_valuable_available_asset;Age_years;Concurrent_Credits;Type_of_apartment;No_of_Credits_at_this_Bank;Occupation;No_of_dependents;Telephone;Foreign_Worker\n",
      "Creditability\n",
      "Account_Balance\n",
      "Duration_of_Credit_monthly\n",
      "Payment_Status_of_Previous_Credit\n",
      "Purpose\n",
      "Credit_Amount\n",
      "Value_Savings_Stocks\n",
      "Length_of_current_employment\n",
      "Instalment_per_cent\n",
      "Sex_Marital_Status\n",
      "Guarantors\n",
      "Duration_in_Current_address\n",
      "Most_valuable_available_asset\n",
      "Age_years\n",
      "Concurrent_Credits\n",
      "Type_of_apartment\n",
      "No_of_Credits_at_this_Bank\n",
      "Occupation\n",
      "No_of_dependents\n",
      "Telephone\n",
      "Foreign_Worker\n",
      "['Creditability', 'Account_Balance', 'Duration_of_Credit_monthly', 'Payment_Status_of_Previous_Credit', 'Purpose', 'Credit_Amount', 'Value_Savings_Stocks', 'Length_of_current_employment', 'Instalment_per_cent', 'Sex_Marital_Status', 'Guarantors', 'Duration_in_Current_address', 'Most_valuable_available_asset', 'Age_years', 'Concurrent_Credits', 'Type_of_apartment', 'No_of_Credits_at_this_Bank', 'Occupation', 'No_of_dependents', 'Telephone', 'Foreign_Worker']\n",
      "0;1;48;4;1;6331;1;5;4;3;1;4;4;46;3;3;2;3;1;2;1\n",
      "[0, 1, 48, 4, 1, 6331, 1, 5, 4, 3, 1, 4, 4, 46, 3, 3, 2, 3, 1, 2, 1]\n",
      "retio of intrinsic samples: 0.7\n",
      "(20, 1000)\n"
     ]
    }
   ],
   "source": [
    "# data processing\n",
    "def gdata(df):\n",
    "    data=[]\n",
    "    for i in range(len(df[name])):\n",
    "        rowv=[]\n",
    "        ss=''\n",
    "        for x in range(len(df[name][i])):\n",
    "            #rowv=[]\n",
    "            if df[name][i][x]!=';':\n",
    "                ss += df[name][i][x]\n",
    "                #print(ss)\n",
    "            else:\n",
    "                rowv.append(int(ss))\n",
    "                ss=''\n",
    "        rowv.append(int(ss))\n",
    "        data.append(rowv)\n",
    "    return data\n",
    "\n",
    "def gtit(name):\n",
    "    tit=[]\n",
    "    ss=''\n",
    "    for x in range(len(name)):\n",
    "        #rowv=[]\n",
    "        if name[x]!=';':\n",
    "            ss += name[x]\n",
    "            #print(ss)\n",
    "        else:\n",
    "            tit.append(ss)\n",
    "            ss=''\n",
    "    tit.append(ss)\n",
    "    return tit\n",
    "\n",
    "print(name)\n",
    "titg=gtit(name)\n",
    "for x in range(len(titg)):\n",
    "    print(titg[x])\n",
    "print(titg)\n",
    "    \n",
    "\n",
    "\n",
    "datag=gdata(df)\n",
    "print(df[name][919])\n",
    "print(datag[919])\n",
    "\n",
    "\n",
    "Tlabel=tf.ones(np.shape(tf.transpose(datag,[1,0])[0,:]))-np.array(tf.transpose(datag,[1,0])[0,:],np.float64)\n",
    "retio_intrinsic=1-np.sum(Tlabel)/len(Tlabel)\n",
    "print(Tlabel)\n",
    "print(\"retio of intrinsic samples: {}\".format(retio_intrinsic)) \n",
    "Data=np.array(tf.transpose(datag,[1,0]),np.float64)[1:,:] \n",
    "print(np.shape(Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 1000]\n",
      "Stop Criterion: 0.04172300635169311\n",
      "Stop Criterion: 0.01362955957421532\n",
      "Stop Criterion: 0.0073098712129353914\n",
      "Stop Criterion: 0.0068196930042786034\n",
      "Stop Criterion: 0.006810130460883333\n",
      "Stop Criterion: 0.006810042752252523\n",
      "Stop Criterion: 0.006810042368178341\n",
      "Stop Criterion: 0.006810042367375473\n",
      "Stop Criterion: 0.006810042367374643\n",
      "Stop Criterion: 0.002903295734016509\n",
      "Stop Criterion: 0.0025361118864823907\n",
      "Stop Criterion: 0.0019905209335913283\n",
      "Stop Criterion: 0.001139340378695178\n",
      "Stop Criterion: 0.0011261994345431899\n",
      "Stop Criterion: 0.0010597565526406672\n",
      "Stop Criterion: 0.0007714559865651052\n",
      "Stop Criterion: 0.0006544382631864233\n",
      "Stop Criterion: 0.00038489810074208693\n",
      "Stop Criterion: 0.00023576825307294782\n",
      "Stop Criterion: 0.00011818770840758773\n",
      "Stop Criterion: 3.7803857740678286e-05\n",
      "Stop Criterion: 2.5493437678640737e-05\n",
      "Stop Criterion: 1.1873797279431136e-05\n",
      "Stop Criterion: 3.884116318610258e-06\n",
      "Stop Criterion: 6.689151540769852e-07\n",
      "Stop Criterion: 4.5566906857802e-07\n",
      "Stop Criterion: 2.6194734271379893e-07\n",
      "Stop Criterion: 1.1140046301186351e-07\n",
      "Stop Criterion: 4.2756150292954164e-08\n",
      "[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n",
      "acc by OP: 0.638\n",
      "Precision by OP: 0.34951456310679613\n",
      "recall score by OP: 0.24\n",
      "f1 score by OP: 0.2845849802371541\n",
      "r2 score by OP: -0.7238095531658255\n"
     ]
    }
   ],
   "source": [
    "# test OP\n",
    "n1,n2=np.shape(Data)\n",
    "print([n1,n2])\n",
    "lam=5.5/np.sqrt(n2)\n",
    "print(lam*np.sqrt(n2))\n",
    "th=0.0000000000000001\n",
    "rho=1.5\n",
    "mup=1.25\n",
    "value_sets=(Data, lam, th,rho, mup)\n",
    "H=OP_main(value_sets) \n",
    "#print(Tlabel)\n",
    "print(H.Elabel)\n",
    "acc_op=accuracy_score(Tlabel, H.Elabel)\n",
    "print(\"acc by OP: {}\".format(acc_op)) \n",
    "precision_op=precision_score(Tlabel, H.Elabel)\n",
    "print(\"Precision by OP: {}\".format(precision_op)) \n",
    "rs_op=recall_score(Tlabel, H.Elabel)\n",
    "print(\"recall score by OP: {}\".format(rs_op))  \n",
    "f1_op=f1_score(Tlabel, H.Elabel)\n",
    "print(\"f1 score by OP: {}\".format(f1_op))\n",
    "r2_op=r2_score(Tlabel, H.Elabel)\n",
    "print(\"r2 score by OP: {}\".format(r2_op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(H.Elabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1\n",
      " 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1\n",
      " 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1\n",
      " 1]\n",
      "acc by KNN: 0.671\n",
      "Precision by KNN: 0.4161849710982659\n",
      "recall score by KNN: 0.24\n",
      "f1 score by KNN: 0.3044397463002114\n",
      "r2 score by KNN: -0.5666666933468414\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(tf.transpose(Data,[1,0])) \n",
    "y_pred = kmeans.predict(tf.transpose(Data,[1,0]))\n",
    "print(y_pred)\n",
    "finalacc_kM=accuracy_score(Tlabel, y_pred)\n",
    "print(\"acc by kM: {}\".format(finalacc_kM)) \n",
    "precision_kM=precision_score(Tlabel, y_pred)\n",
    "print(\"Precision by kM: {}\".format(precision_kM)) \n",
    "rs_kM=recall_score(Tlabel, y_pred)\n",
    "print(\"recall score by kM: {}\".format(rs_kM))  \n",
    "f1_kM=f1_score(Tlabel, y_pred)\n",
    "print(\"f1 score by kM: {}\".format(f1_kM))\n",
    "r2_kM=r2_score(Tlabel, y_pred)\n",
    "print(\"r2 score by kM: {}\".format(r2_kM))\n",
    "#score.append(silhouette_score(features, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tf.ones(len(y_pred))-y_pred)\n",
    "#acc_knn=accuracy_score(Tlabel, tf.ones(len(y_pred))-y_pred)\n",
    "#print(\"acc by KNN: {}\".format(acc_knn)) \n",
    "#precision_knn=precision_score(Tlabel, tf.ones(len(y_pred))-y_pred)\n",
    "#print(\"Precision by KNN: {}\".format(precision_knn)) \n",
    "#rs_knn=recall_score(Tlabel, tf.ones(len(y_pred))-y_pred)\n",
    "#print(\"recall score by KNN: {}\".format(rs_knn))  \n",
    "#f1_knn=f1_score(Tlabel, tf.ones(len(y_pred))-y_pred)\n",
    "#print(\"f1 score by KNN: {}\".format(f1_knn))\n",
    "#r2_knn=r2_score(Tlabel, tf.ones(len(y_pred))-y_pred)\n",
    "#print(\"r2 score by KNN: {}\".format(r2_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 0 0 0\n",
      " 0 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0]\n",
      "acc by Gaussian Mixture: 0.359\n",
      "Precision by Gaussian Mixture: 0.3064699205448354\n",
      "recall score by Gaussian Mixture: 0.9\n",
      "f1 score by Gaussian Mixture: 0.4572396274343776\n",
      "r2 score by Gaussian Mixture: -2.052381004362691\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gm=GaussianMixture(n_components=2,n_init=10)\n",
    "gm.fit(tf.transpose(Data,[1,0]))\n",
    "gm.converged_\n",
    "gm.n_iter_\n",
    "y_gm=gm.predict(tf.transpose(Data,[1,0]))\n",
    "#gm.predict_proba(tf.transpose(Data,[1,0]))\n",
    "print(y_gm)\n",
    "finalacc_gm=accuracy_score(Tlabel, tf.ones(len(y_gm))-y_gm)\n",
    "print(\"acc by Gaussian Mixture: {}\".format(finalacc_gm)) \n",
    "precision_gm=precision_score(Tlabel, tf.ones(len(y_gm))-y_gm)\n",
    "print(\"Precision by Gaussian Mixture: {}\".format(precision_gm)) \n",
    "rs_gm=recall_score(Tlabel, tf.ones(len(y_gm))-y_gm)\n",
    "print(\"recall score by Gaussian Mixture: {}\".format(rs_gm))  \n",
    "f1_gm=f1_score(Tlabel, tf.ones(len(y_gm))-y_gm)\n",
    "print(\"f1 score by Gaussian Mixture: {}\".format(f1_gm))\n",
    "r2_gm=r2_score(Tlabel, tf.ones(len(y_gm))-y_gm)\n",
    "print(\"r2 score by Gaussian Mixture: {}\".format(r2_gm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gm=GaussianMixture(n_components=2,n_init=10)\n",
    "gm.fit(tf.transpose(Data,[1,0]))\n",
    "gm.converged_\n",
    "gm.n_iter_\n",
    "y_gm=gm.predict(tf.transpose(Data,[1,0]))\n",
    "#gm.predict_proba(tf.transpose(Data,[1,0]))\n",
    "print(y_gm)\n",
    "finalacc_gm=accuracy_score(Tlabel, y_gm)\n",
    "print(\"acc by Gaussian Mixture: {}\".format(finalacc_gm)) \n",
    "precision_gm=precision_score(Tlabel, y_gm)\n",
    "print(\"Precision by Gaussian Mixture: {}\".format(precision_gm)) \n",
    "rs_gm=recall_score(Tlabel, y_gm)\n",
    "print(\"recall score by Gaussian Mixture: {}\".format(rs_gm))  \n",
    "f1_gm=f1_score(Tlabel, y_gm)\n",
    "print(\"f1 score by Gaussian Mixture: {}\".format(f1_gm))\n",
    "r2_gm=r2_score(Tlabel, y_gm)\n",
    "print(\"r2 score by Gaussian Mixture: {}\".format(r2_gm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Insurance Company (TIC) Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "(85, 4000)\n",
      "retio of intrinsic samples: 0.9405\n"
     ]
    }
   ],
   "source": [
    "#loading TIC\n",
    "df_label = pd.read_csv('tic_2000_target_data.csv')\n",
    "df_label.head(3)\n",
    "TlabelTIC=np.array(df_label)[:,0]\n",
    "print(len(TlabelTIC)) \n",
    "df_Data = pd.read_csv('tic_2000_eval_data.csv')\n",
    "df_Data.head(3)\n",
    "DataTIC=tf.transpose(np.array(df_Data,np.float64),[1,0])\n",
    "print(np.shape(DataTIC))\n",
    "retio_intrinsic=1-np.sum(TlabelTIC)/len(TlabelTIC)\n",
    "print(\"retio of intrinsic samples: {}\".format(retio_intrinsic)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uM3i2rVwbzV9",
    "outputId": "ca5d4dc3-4dee-425c-fc65-f0b25ae93cb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85, 4000]\n",
      "Stop Criterion: 0.364498481840813\n",
      "Stop Criterion: 0.2911324512061364\n",
      "Stop Criterion: 0.25060778515269144\n",
      "Stop Criterion: 0.1582460955986047\n",
      "Stop Criterion: 0.07336364437181367\n",
      "Stop Criterion: 0.030316496556801985\n",
      "Stop Criterion: 0.008174521466537908\n",
      "Stop Criterion: 0.001601751821392138\n",
      "Stop Criterion: 0.0005918295824999644\n",
      "Stop Criterion: 0.0003286994561150469\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/st/r3f100zj5m59hc4n539wy4300000gn/T/ipykernel_29692/2550423709.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mvalue_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataTIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOP_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTlabelTIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/st/r3f100zj5m59hc4n539wy4300000gn/T/ipykernel_29692/2625264917.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value_sets)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mX_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE_int\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mvalue_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambda_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOP_ADMM_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/st/r3f100zj5m59hc4n539wy4300000gn/T/ipykernel_29692/2625264917.py\u001b[0m in \u001b[0;36mOP_ADMM_main\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m#print(self.Lambda[-1][0,0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUpdata_E\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUpdata_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUpdata_Lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/st/r3f100zj5m59hc4n539wy4300000gn/T/ipykernel_29692/2625264917.py\u001b[0m in \u001b[0;36mUpdata_E\u001b[0;34m(self, Data, X, Lambda)\u001b[0m\n\u001b[1;32m     99\u001b[0m         ''' \n\u001b[1;32m    100\u001b[0m         \u001b[0mTemp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_col\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mTemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/st/r3f100zj5m59hc4n539wy4300000gn/T/ipykernel_29692/2625264917.py\u001b[0m in \u001b[0;36msparse_col\u001b[0;34m(self, E, tau)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m            \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    977\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10354\u001b[0m         \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"begin_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10355\u001b[0m         \u001b[0;34m\"ellipsis_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"new_axis_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10356\u001b[0;31m         \"shrink_axis_mask\", shrink_axis_mask)\n\u001b[0m\u001b[1;32m  10357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10358\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test OP\n",
    "n1,n2=np.shape(DataTIC)\n",
    "print([n1,n2])\n",
    "lam=5/np.sqrt(n2)\n",
    "th=0.0000000000000001\n",
    "rho=1.5\n",
    "mup=1.25\n",
    "value_sets=(DataTIC, lam, th,rho, mup)\n",
    "H=OP_main(value_sets) \n",
    "print(TlabelTIC)\n",
    "print(H.Elabel)\n",
    "acc_op=accuracy_score(TlabelTIC, H.Elabel)\n",
    "print(\"acc by OP: {}\".format(acc_op)) \n",
    "precision_op=precision_score(TlabelTIC, H.Elabel)\n",
    "print(\"Precision by OP: {}\".format(precision_op)) \n",
    "rs_op=recall_score(TlabelTIC, H.Elabel)\n",
    "print(\"recall score by OP: {}\".format(rs_op))  \n",
    "f1_op=f1_score(TlabelTIC, H.Elabel)\n",
    "print(\"f1 score by OP: {}\".format(f1_op))\n",
    "r2_op=r2_score(TlabelTIC, H.Elabel)\n",
    "print(\"r2 score by OP: {}\".format(r2_op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc by KNN: 0.65075\n",
      "Precision by KNN: 0.0821917808219178\n",
      "recall score by KNN: 0.4789915966386555\n",
      "f1 score by KNN: 0.14030769230769233\n",
      "r2 score by KNN: -5.24109292839943\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(tf.transpose(DataTIC,[1,0])) \n",
    "y_pred = kmeans.predict(tf.transpose(DataTIC,[1,0]))\n",
    "acc_knn=accuracy_score(TlabelTIC, y_pred)\n",
    "print(\"acc by KNN: {}\".format(acc_knn)) \n",
    "precision_knn=precision_score(TlabelTIC, y_pred)\n",
    "print(\"Precision by KNN: {}\".format(precision_knn)) \n",
    "rs_knn=recall_score(TlabelTIC, y_pred)\n",
    "print(\"recall score by KNN: {}\".format(rs_knn))  \n",
    "f1_knn=f1_score(TlabelTIC, y_pred)\n",
    "print(\"f1 score by KNN: {}\".format(f1_knn))\n",
    "r2_knn=r2_score(TlabelTIC, y_pred)\n",
    "print(\"r2 score by KNN: {}\".format(r2_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 0. 1. ... 1. 1. 0.], shape=(4000,), dtype=float32)\n",
      "acc by KNN: 0.34925\n",
      "Precision by KNN: 0.047455032529659394\n",
      "recall score by KNN: 0.5210084033613446\n",
      "f1 score by KNN: 0.08698702209750964\n",
      "r2 score by KNN: -10.628893981835159\n"
     ]
    }
   ],
   "source": [
    "#print(tf.ones(len(y_pred))-y_pred)\n",
    "#acc_knn=accuracy_score(TlabelTIC, tf.ones(len(y_pred))-y_pred)\n",
    "#print(\"acc by KNN: {}\".format(acc_knn)) \n",
    "#precision_knn=precision_score(TlabelTIC, tf.ones(len(y_pred))-y_pred)\n",
    "#print(\"Precision by KNN: {}\".format(precision_knn)) \n",
    "#rs_knn=recall_score(TlabelTIC, tf.ones(len(y_pred))-y_pred)\n",
    "#print(\"recall score by KNN: {}\".format(rs_knn))  \n",
    "#f1_knn=f1_score(TlabelTIC, tf.ones(len(y_pred))-y_pred)\n",
    "#print(\"f1 score by KNN: {}\".format(f1_knn))\n",
    "#r2_knn=r2_score(TlabelTIC, tf.ones(len(y_pred))-y_pred)\n",
    "#print(\"r2 score by KNN: {}\".format(r2_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.mixture import GaussianMixture\n",
    "#gm=GaussianMixture(n_components=2,n_init=10)\n",
    "#gm.fit(tf.transpose(DataTIC,[1,0]))\n",
    "#gm.converged_\n",
    "#gm.n_iter_\n",
    "#y_gm=gm.predict(tf.transpose(DataTIC,[1,0]))\n",
    "##gm.predict_proba(tf.transpose(Data,[1,0]))\n",
    "#print(y_gm)\n",
    "#finalacc_gm=accuracy_score(TlabelTIC, tf.ones(len(y_gm))-y_gm)\n",
    "#print(\"acc by Gaussian Mixture: {}\".format(finalacc_gm)) \n",
    "#precision_gm=precision_score(TlabelTIC, tf.ones(len(y_gm))-y_gm)\n",
    "#print(\"Precision by Gaussian Mixture: {}\".format(precision_gm)) \n",
    "#rs_gm=recall_score(TlabelTIC, tf.ones(len(y_gm))-y_gm)\n",
    "#print(\"recall score by Gaussian Mixture: {}\".format(rs_gm))  \n",
    "#f1_gm=f1_score(TlabelTIC, tf.ones(len(y_gm))-y_gm)\n",
    "#print(\"f1 score by Gaussian Mixture: {}\".format(f1_gm))\n",
    "#r2_gm=r2_score(TlabelTIC, tf.ones(len(y_gm))-y_gm)\n",
    "#print(\"r2 score by Gaussian Mixture: {}\".format(r2_gm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "acc by Gaussian Mixture: 0.127\n",
      "Precision by Gaussian Mixture: 0.05955603681645912\n",
      "recall score by Gaussian Mixture: 0.9243697478991597\n",
      "f1 score by Gaussian Mixture: 0.1119023397761953\n",
      "r2 score by Gaussian Mixture: -14.600498572634796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gm=GaussianMixture(n_components=2,n_init=10)\n",
    "gm.fit(tf.transpose(DataTIC,[1,0]))\n",
    "gm.converged_\n",
    "gm.n_iter_\n",
    "y_gm=gm.predict(tf.transpose(DataTIC,[1,0]))\n",
    "#gm.predict_proba(tf.transpose(Data,[1,0]))\n",
    "print(y_gm)\n",
    "finalacc_gm=accuracy_score(TlabelTIC,y_gm)\n",
    "print(\"acc by Gaussian Mixture: {}\".format(finalacc_gm)) \n",
    "precision_gm=precision_score(TlabelTIC, y_gm)\n",
    "print(\"Precision by Gaussian Mixture: {}\".format(precision_gm)) \n",
    "rs_gm=recall_score(TlabelTIC, y_gm)\n",
    "print(\"recall score by Gaussian Mixture: {}\".format(rs_gm))  \n",
    "f1_gm=f1_score(TlabelTIC, y_gm)\n",
    "print(\"f1 score by Gaussian Mixture: {}\".format(f1_gm))\n",
    "r2_gm=r2_score(TlabelTIC, y_gm)\n",
    "print(\"r2 score by Gaussian Mixture: {}\".format(r2_gm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "OP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
